# 古诗生成模型调研

中文古诗生成任务，是文本生成中一个比较常见的任务。下面基于该任务做生成模型对比调研。

#### 目的：
1. 评测[textgen](https://github.com/shibing624/textgen)库的生成模型代码完整性及可用性；
2. 评测[GPT2](https://github.com/shibing624/textgen/tree/main/textgen/language_modeling)和[T5](https://github.com/shibing624/textgen/tree/main/textgen/t5)模型在对联生成上的效果，并对比两者的差异。


## 数据集

https://github.com/chinese-poetry/chinese-poetry ，选取其中唐朝和宋朝的诗，共310090首诗。

样本：

|作者|题目|诗句|
|----|----|----|
|郎士元|夜泊湘江|湘山木落洞庭波，湘水连云秋雁多。寂寞舟中谁借问，月明只自听渔歌。|
|宋白|宫词其九一|虢国威仪过薛王，担夫争路气扬扬。宫嫔后出香车送，飐碎钗头玉凤凰。|



## T5模型

T5模型一种Encoder-Decoder架构，其中输入和输出都是文本序列。
这使它能够灵活地执行任何自然语言处理任务，而无需以任何方式修改模型架构。这也意味着训练一个T5模型可以同时执行多个任务，只需要给它不同*prefix*即可。

关于T5模型可以参考paper：*[Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)* 

#### 使用步骤

使用步骤：

1. 初始化 `T5Model`
2. 训练模型 `train_model()`
3. 评估模型 `eval_model()`
4. 预测 `predict()`

### 训练及预测

查看 [examples/T5/T5_Finetune_Chinese_Poem.ipynb](https://github.com/shibing624/textgen/blob/main/examples/T5/T5_Finetune_Chinese_Poem.ipynb) ，里面包括训练和预测。

使用全量数据训练5个epochs。

### 结果预测

|prefix|input_text|target_text|pred|
|:-- |:--- |:--- |:-- |
|作诗：|灵响词五|存念长在心，展转无停音。可怜清爽夜，静听秋蝉吟。|灵响传空有,灵音出混茫。玉绳低缭绕,珠树圆光。|



## GPT2模型

GPT2模型也是从Transformer改进来的，T5同时有编码器和解码器，GPT2只有解码器，所以对于单向的文本生成任务特别适合。

#### 使用步骤

由于GPT2模型本质是训练一个语言模型，所以训练时用`textgen.language_generation.LanguageModelingModel`，
预测时用`textgen.language_modeling.LanguageGenerationModel`。

使用步骤：

1. 初始化 `LanguageModelingModel` 和对应的`tokenizer`
2. 训练模型 `train_model()`
3. 评估模型 `eval_model()`
4. 预测，调用`LanguageGenerationModel`的`generate`方法

### 训练及预测

查看 [examples/language_generation/GPT2_Finetune_Chinese_Poem.ipynb](https://github.com/shibing624/textgen/blob/main/examples/language_generation/GPT2_Finetune_Chinese_Poem.ipynb) ，里面包括训练和预测。

使用全量数据训练5个epochs。

### 结果预测

|input_text|target_text|pred|
|:--- |:--- |:-- |
|灵响词五|存念长在心，展转无停音。可怜清爽夜，静听秋蝉吟。|三五元宵，玉蟾夜已长。天上三声，无人知。|

## 预测结果对比

|input_text|target_text|GPT2预测|T5预测|哪个模型效果好|
|:--- |:--- |:-- |:-- |:--:|
|灵响词五|存念长在心，展转无停音。可怜清爽夜，静听秋蝉吟。|灵响词五首五</s>作者：彭汝砺三五元宵，玉蟾夜已长。天上三声，无人知。|灵响传空有,灵音出混茫。玉绳低缭绕,珠树圆光。|都差|
|送王炎弼赴山阳守以兵卫森|盛世须材杰，高名动圣明。一麾淮海去，青旆拥千兵。|送王炎弼赴山阳守以兵卫森</s>作者：韩愈山阳第一人，一生风味颇相忘。一气俱然已足叹，百年中间一道心。江山久在千顷远，我独|君家大江南,我家大江南。君家大江南,我家江南南。我行江南来,君行亦良苦。君行向何许,我行适所遇。君行向何许,我行|GPT2好|
|示杨仲质</s>作者：释印肃|谁识一微尘，于中藏本佛。时时常放光，照烛一切物。只许信心人，在处无轻忽。这回如未应，不离金刚骨。逢本分钳锤，煆成非外物。|示杨仲质</s>作者：释印肃一月云水秋，空山万壑春。何年一月晓，幽壑未回头。|一闲身入道场,中无物可思量。只将此意超情量,不觉如今已觉忙。|T5好|
|池莲四咏分韵叶</s>作者：刘子翚|鬰烈香浮雨，团栾绿荫波。近堤千叶乱，知有画船过。|池莲四咏分韵叶</s>作者：刘子翚月在湖心月更清，天教谁识此娟娟。若人未得三年后，便问三更有几人。|池荷红,水莲绿。风来吹细香,雨过飘新馥。|GPT2好|
|艳情代郭氏荅卢照邻|迢迢芊路望芝田，眇眇函关恨蜀川。归云已落涪江外，还雁应过洛水瀍。洛水傍连帝城侧，帝宅层甍垂凤翼。铜驼路上柳千条，金谷园中花几色。|艳情代郭氏荅卢照邻江南四大玉龙瑞，三洞天目玉蛇神。三洞天目天目玉，画像云中石墨。玉山真上，千里江涛入洞天。|君不见汉宫娇艳如花红,宫中美人美如玉。又不见汉宫美人美如玉,春昼春昼春昼同。春来春去能几时,绿鬓朱顔不长好|都差|
|鲜于东之晋伯之子赠诗次韵</s>作者：晁公遡|高帘不卷户长开，须子时时着屣来。一坐清风生白羽，九衢乌帽失黄埃。|鲜于东之晋伯之子赠诗次韵</s>作者：晁公遡君臣一笑便如冰，何以饮时得酒量。一声流水自相宜，两颊红颊更相亲。|君家文采似三都,更向诸郎识大苏。白首相逢如问我,爲言衰病不枝梧。|都差|
|寓宝相有作</s>作者：陆游|扫地镜面清，烧香云气润。道人敬爱客，危坐目不瞬。童子髠两髦，经禅亦精进。我来愿同龛，欢喜无少吝。临堂坐夜分，佛灯看堕烬。清晨爽如|寓宝相有作</s>作者：陆游白鸟啼风起晚凉，花团露照山阴。一枝长伴双眸看，一首共看一枝红。|客有成都客,来从海上州。相逢虽邂逅,一醉却迟留。野店供茶,山城送酒楼。明朝又何处,回首不堪愁。|都差|
|丹元子步天歌东方七宿</s>作者：王希明|亢，四星恰如弯弓状。大角一星直上明，折威七子亢下横。大角左右摄提星，三三相似如鼎形。折威下左顿顽星，两箇斜安黄色精。顽下二星号阳|丹元子步天歌东方七宿</s>作者：王希明西风吹起九霄风，不知西路有。今晚此仙台上，十五千年一一回。|四星形状如钩陈。天狗四星名木星,天马六星号天星。天狗四星名天星,天狗五星号天星。|都差|
|重九</s>作者：朱弁|九日今何地，寒深紫塞霜。敢嫌芦酒浊，且对菊花甞。岁月双蓬鬓，干坤百战场。赐茰知未举，夢自识鸳行。|重九</s>作者：朱弁重九今日一，重九重九重。重九重九重，重九重九重。重九重九重，重九重重。重九重九重，重九重重。重九重|九日登高望故乡,黄花满地菊成行。故人不见空垂泪,惟有黄花似故乡。|T5好|
|简如臯赵买盐</s>作者：宋伯仁|倾盖相逢尽故人，如君喜色更津津。三更虽共金樽月，半日难留玉麈尘。淮海浮名徒惹手，田园归计好谋身。何时同醉孤山路，笑捻梅花问早春。|简如臯赵买盐</s>作者：宋伯仁三峡两州同列前，一水相逢相见倍。故乡不敢访蜀山，今日何方作郡。|老去无成事,闲中得句稀。风烟迷古寺,灯火傍寒扉。客裏逢春尽,吟边得句稀。梅花如见问,爲道故人稀。|都差|

分析：

1. 10个预测case，6个效果都差，说明中文古诗生成任务很难，仅仅依赖题目和作者名，两个模型都无法准确生成切题的诗句，生成的结果只是满足了字数对称、词性对齐、词面对齐，形似，
 语义对仗工整还差点儿，平仄合律、文意切题也不满足。
2. 剩下4个case，其中GPT2效果好的有2个，T5好的有2个，评估数据少，不能说明哪个更合适。
3. 由于数据集有30万首诗，T5模型难拟合，V100GPU机器单卡训练12小时，跑5个epoch后，loss依然在0.3左右，未明显下降。


## 展望

古诗创作的基本要求是：平仄合律，对仗工整，文意切题。

三者相互依存，不可偏废。平仄合律是基础，不合律的对联就是不合格的对联。对仗工整是关键，
对仗不工整，即使平仄合律，也只能滥竽充数。文意切题是目的，平仄合律、对仗工整而文意不切题，就是无的放矢，甚至会产生相反的效果。

1. 后续调研[SongNet](https://zhuanlan.zhihu.com/p/162216597)，该模型加入了模板和韵律特征，可以同时保证生成文本的格式正确、韵律合理、句子完整等基本的质量要求。
2. 改基于题目写诗，变为基于原诗仿写新诗，降低生成任务难度，提高生成效果。
